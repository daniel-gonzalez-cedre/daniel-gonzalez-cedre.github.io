\input{preamble.tex}
\input{environments.tex}
\input{definitions.tex}

\begin{document}

\title{Discrete Mathematics}
\author{Daniel Gonzalez Cedre}
\date{University of Notre Dame \\ Spring of 2023}
\maketitle

% # \renewcommand\listoflistingscaption{List of Algorithms}
% # \listoflistings

\setcounter{chapter}{4}
\chapter{Complexity Theory}

\section{Recursion}
\begin{idea}[Recurrence Relation]
    A \emph{recurrence relation} is a sequence $\bracket{x_i}_{i \in \N}$
    over some set of values (for our purposes, usually $\N$ or $\Z$)
    that is useful for \emph{modeling} some physical phenomenon or process (such as an algorithm).
    Even if the phenomena being modeled would not be immediately described as ``recursive'' in nature,
    recurrence relations can often be used to give a recursive \emph{interpretation}
    amenable to formal analysis using induction.
\end{idea}

\begin{definition}[Fibonacci Sequence]
    We define the Fibonacci sequence $\bracket{\mathcal{F}_i}_{i \in \N}$ by the recursive construction
%     \[
% \setlength{\abovedisplayskip}{1ex}
% \setlength{\belowdisplayskip}{1ex}
%         \mathcal{F}_n = 
%         \begin{cases}
%             0 &\text{ if } n = 0\\
%             1 &\text{ if } n = 1\\
%             \mathcal{F}_{n - 1} + \mathcal{F}_{n - 2} &\text{ if } n \in \N \setminus \set*{0, 1}.
%         \end{cases}
%     \]
    \begin{align*}
        \mathcal{F}_0 &\defn 0\\
        \mathcal{F}_1 &\defn 1\\
        \mathcal{F}_n &\defn \mathcal{F}_{n - 1} + \mathcal{F}_{n - 2}
            ~~~~\text{ if } n \in \N \setminus \set*{0, 1}
    \end{align*}
\end{definition}

\begin{definition}[Simple Search]
    ~

\begin{center}
\begin{minipage}{.5\linewidth}
\begin{figure}[H]
\renewcommand\figurename{Algorithm}
\begin{minted}[
    linenos,
    mathescape,
    fontsize=\footnotesize,
    % bgcolor=bg,
]{python}
# recursively searches through the list L for the element x
def simple_search(L: list, x) -> bool:
    if len(L) == 0:
        return False
    return (L[0] == x) or search(L[1:], x)
\end{minted}
\caption{Simple Search}\label{alg:simplesearch}
\end{figure}
\end{minipage}
\end{center}

\end{definition}

\begin{definition}[Bubble Sort]
    ~

\begin{center}
\begin{minipage}{.5\linewidth}
\begin{figure}[H]
\renewcommand\figurename{Algorithm}
\begin{minted}[
    linenos,
    mathescape,
    fontsize=\footnotesize,
    % bgcolor=bg,
]{python}
# recursively propagate the largest element to the end of the list
def bubble(L: list) -> list:
    if L[0] > L[1]:
        L = [L[1], L[0]] + L[2:]  # swap the first two elements of the list
    if len(L) == 2:
        return L
    else:
        return [L[0]] + bubble(L[1:])

# recursively sorts the list L
def bubble_sort(L: list) -> list:
    if len(L) <= 1:
        return L
    else:
        L = bubble(L)
        return bubble_sort(L[:-1]) + [L[-1]]
\end{minted}
\caption{Bubble Sort}\label{alg:bubblesort}
\end{figure}
\end{minipage}
\end{center}

\end{definition}

\begin{definition}[Merge Sort]
    ~

\begin{center}
\begin{minipage}{.5\linewidth}
\begin{figure}[H]
\renewcommand\figurename{Algorithm}
\begin{minted}[
    linenos,
    mathescape,
    fontsize=\footnotesize,
    % bgcolor=bg,
]{python}
# recursively merge the sorted lists L and R into one sorted list
def merge_sort(L: list, R: list) -> list:
    raise NotImplementedError

# recursively sorts the list L
def merge_sort(L: list) -> list:
    n = len(L)
    if n <= 1:
        return L
    else:
        left = merge_sort(L[:n // 2])
        right = merge_sort(L[n // 2:])
        return merge(left, right)
\end{minted}
\caption{Merge Sort}\label{alg:mergesort}
\end{figure}
\end{minipage}
\end{center}

\end{definition}

\begin{intuition}[Function]
    We use the notation $f: X \to Y$ to denote that $f$ is a function
    whose \emph{domain} is $X$ and whose \emph{codomain} is $Y$,
    meaning that $f$ takes inputs from $X$ and produces values in $Y$.
    When we take an element $x \in X$ and \emph{apply} $f$ to $x$,
    we denote the produced result by the notation $f(x)$, which satisfies $f(x) \in Y$.
    The defining characteristic of functions is, intuitively,
    that they \emph{must} produce \emph{exactly one} output for any valid input.
    However, we need a set-theoretic representation of this idea.

    The simplest intuition here for the set-theoretic implementation is to think of the graph of a function,
    which (for the traditional real-valued functions you have encountered in grade school and calculus)
    consists of ordered pairs $(x, y)$, where the $x$ and $y$ were typically real numbers.
    Drawing on your prior experience with functions, we know:
    \begin{enumerate}
        \item[I.]
            They should be defined on the entirety of their \emph{domain},
            meaning that we should have $(x, y)$ ordered pairs for every value of $x$ from the domain.
            In fact, in grade school you were probably told that the set of input values
            where the function was defined was, by definition, the domain of the function.
        \item[II.]
            They should pass the \emph{vertical line test},
            meaning that there is no more than one if $(x, y_1)$ and $(x, y_2)$ are both points
            on the graph of the function, then $y_1 = y_2$.
            This corresponds precisely to the idea that
            a function's output is \emph{solely} determined by its input---%
            that the same input can not lead to two different outputs.
    \end{enumerate}
\end{intuition}

\begin{definition}[Unique Existential Quantification]
    If $\varphi$ is a {\wff}, we use the notation $\exists! x \pn*{\varphi(x)}$ to denote that
    \emph{there exists a unique} $x$ that satisfies $\varphi$.
    Formally,
    \[
        \exists! x \pn*{\varphi(x)} \iffdefn \exists x \pn*{\varphi(x) \meet \forall y \pn*{\varphi(y) \implies y = x}}
    \]
\end{definition}

\begin{definition}[Function]
    We write $f: X \to Y$ to mean that $f$ is a function with domain $X$ and co-domain $Y$ {\ifandonlyif}
    \begin{enumerate}
        \item[I.]
            $f \subseteq X \times Y$
        \item[II.]
            $\pn*{\forall x \in X}\pn*{\exists ! y \in Y}\pn*{(x, y) \in f}$
    \end{enumerate}
\end{definition}

\section{Asymptotic Analysis}
\begin{definition}[Landau Notation]
    Let $X \subseteq \R$ and $Y \subseteq \R$ and consider two functions $f: X \to Y$ and $g: X \to Y$.
    We define here what it means for $g$ to \emph{asymptotically dominate} $f$,
    which is usually read as ``$f$ is big-oh of $g$,''
    with the following Landau notation:
    \[
        f \in \O{g} \iffdefn \pn*{\exists n \in \R}\pn*{\exists C \in \R}\pn*{\forall x \in X}
                             \pn*{n \leq x \implies \abs{f(x)} \leq C \abs{g(x)}}.
    \]
    Intuitively, this is saying that a constant multiple $g$ lies permanently above $f$
    \emph{everywhere after some point}.

    For our purposes here, we only consider functions that map numbers to numbers,
    so $X$ and $Y$ could be $\N$, $\Z$, $\Q$, $\R$, or any combination of subsets of those.
    If we wanted to, we could generalize even further by noticing that
    the only impositions we actually have to make on our domain and codomain are
    a definition for \emph{scalar multiplication} on $Y$,
    a notion of \emph{absolute value} $\abs{\cdot}$ on $Y$,
    and \emph{partial orders} $\leq$ on both $X$ and $Y$.
\end{definition}

\begin{example}
    Let's show that $f \in \O{g}$, $g \in \O{f}$, and $h \not \in \O{f}$ for the functions defined below:
    % Let $f: \R \to \R$, $g: \R \to \R$, and $h: \R \to \R$ given by the definitions below:
    \begin{align*}
        f: \R \to \R~~\text{ defined by }~~f(x) &\defn x\\
        g: \R \to \R~~\text{ defined by }~~g(x) &\defn 2x + 5\\
        h: \R \to \R~~\text{ defined by }~~h(x) &\defn x^2
    \end{align*}
    \begin{proof}[Proof of $f \in \O{g}$]
    \end{proof}
    \begin{proof}[Proof 2]
    \end{proof}
    \begin{proof}[Proof 3]
    \end{proof}
\end{example}

\end{document}
